{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "45b7df71",
   "metadata": {},
   "source": [
    "# Fantasy Baseball Redraft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92317a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gym import spaces\n",
    "import numpy as np\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers.legacy import Adam\n",
    "import pandas as pd\n",
    "import gym\n",
    "\n",
    "class SimpleFantasyBaseballEnv(gym.Env):\n",
    "    metadata = {'render.modes': ['human']}\n",
    "    \n",
    "    def __init__(self, player_stats, scoring_rules, positions, position_weights, num_teams=10):\n",
    "        super(SimpleFantasyBaseballEnv, self).__init__()\n",
    "        self.player_stats = player_stats\n",
    "        self.scoring_rules = scoring_rules\n",
    "        self.positions = positions\n",
    "        self.position_weights = position_weights\n",
    "        self.num_teams = num_teams\n",
    "        self.num_rounds = sum(positions.values())\n",
    "        \n",
    "        self.action_space = spaces.Discrete(len(self.player_stats))\n",
    "        self.observation_space = spaces.Discrete(self.num_teams * self.num_rounds)\n",
    "        self.reset()\n",
    "    \n",
    "    def reset(self):\n",
    "        self.teams = {i: {pos: [] for pos in self.positions} for i in range(self.num_teams)}\n",
    "        self.available_players = list(self.player_stats.keys())\n",
    "        \n",
    "        self.available_players.sort(key=lambda player: (\n",
    "            -self.player_stats[player].get('woba', 0), \n",
    "            -self.player_stats[player].get('p_win', 0)\n",
    "        ))\n",
    "        \n",
    "        self.draft_order = self.generate_draft_order()\n",
    "        self.current_pick = 0\n",
    "        return np.zeros(len(self.player_stats[self.available_players[0]]) - 1)\n",
    "    \n",
    "    def generate_draft_order(self):\n",
    "        draft_order = []\n",
    "        for round in range(self.num_rounds):\n",
    "            if round % 2 == 0:\n",
    "                draft_order.extend(range(self.num_teams))\n",
    "            else:\n",
    "                draft_order.extend(range(self.num_teams - 1, -1, -1))\n",
    "        return draft_order\n",
    "    \n",
    "    def step(self, action):\n",
    "        if action < 0 or action >= len(self.available_players):\n",
    "            raise ValueError(f\"Invalid action: {action}. Must be within range [0, {len(self.available_players)-1}]\")\n",
    "        \n",
    "        player = self.available_players[action]\n",
    "        team_id = self.draft_order[self.current_pick]\n",
    "        \n",
    "        player_position = self.player_stats[player]['position']\n",
    "        \n",
    "        if player_position not in self.positions or len(self.teams[team_id][player_position]) >= self.positions[player_position]:\n",
    "            return np.zeros(len(self.player_stats[player]) - 1), -1, self.current_pick >= len(self.draft_order) - 1, {}\n",
    "        \n",
    "        self.teams[team_id][player_position].append(player)\n",
    "        self.available_players.remove(player)\n",
    "        \n",
    "        self.current_pick += 1\n",
    "        reward = self._calculate_reward(team_id, player_position)\n",
    "        done = self.current_pick >= len(self.draft_order)\n",
    "        return np.array(list(self.player_stats[player].values())[1:]), reward, done, {}\n",
    "    \n",
    "    def _calculate_reward(self, team_id, player_position):\n",
    "        team_reward = 0\n",
    "        for pos in self.teams[team_id]:\n",
    "            for player in self.teams[team_id][pos]:\n",
    "                player_stats = self.player_stats[player]\n",
    "                position_weight = self.position_weights.get(pos, 1)\n",
    "                for stat, value in player_stats.items():\n",
    "                    if stat == 'woba':\n",
    "                        team_reward += self.scoring_rules[stat] * value * position_weight * 2\n",
    "                    elif stat == 'p_win':\n",
    "                        team_reward += self.scoring_rules[stat] * value * position_weight * 1.5\n",
    "                    elif stat in self.scoring_rules:\n",
    "                        team_reward += self.scoring_rules[stat] * value * position_weight\n",
    "        return team_reward\n",
    "\n",
    "    def render(self, mode='human'):\n",
    "        print(f'Teams: {self.teams}')\n",
    "        print(f'Current Pick: {self.current_pick}')\n",
    "\n",
    "# Load player stats from Excel file\n",
    "df = pd.read_excel('player_stats2.xlsx')\n",
    "\n",
    "player_stats = df.set_index('name').T.to_dict()\n",
    "for player, stats in player_stats.items():\n",
    "    if 'position' in stats:\n",
    "        stats['position'] = stats['position'].strip()\n",
    "\n",
    "scoring_rules = {\n",
    "    'home_run': 4,\n",
    "    'r_total_stolen_base': 2,\n",
    "    'woba': 100,\n",
    "    'p_save': 5,\n",
    "    'p_win': 6,\n",
    "    'xobp': -3,\n",
    "}\n",
    "\n",
    "positions = {\n",
    "    'C': 1,\n",
    "    '1B': 2,\n",
    "    '2B': 2,\n",
    "    '3B': 2,\n",
    "    'SS': 2,\n",
    "    'OF': 5,\n",
    "    'P': 10,\n",
    "}\n",
    "\n",
    "position_weights = {\n",
    "    'C': 1,\n",
    "    '1B': 2,\n",
    "    '2B': 2,\n",
    "    '3B': 2,\n",
    "    'SS': 3,\n",
    "    'OF': 4,\n",
    "    'P': 5,\n",
    "}\n",
    "\n",
    "env = SimpleFantasyBaseballEnv(player_stats, scoring_rules, positions, position_weights)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(8, input_dim=6, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(env.action_space.n, activation='linear'))\n",
    "model.compile(loss='mse', optimizer=Adam(learning_rate=0.01))\n",
    "\n",
    "num_episodes = 75\n",
    "gamma = 0.95\n",
    "epsilon = 1.0\n",
    "epsilon_decay = 0.995\n",
    "epsilon_min = 0.01\n",
    "\n",
    "replay_buffer = []\n",
    "buffer_size = 10000\n",
    "batch_size = 32\n",
    "\n",
    "for episode in range(num_episodes):\n",
    "    state = env.reset()\n",
    "    state = np.reshape(state, [1, 6])\n",
    "    done = False\n",
    "    pick_count = 0\n",
    "    max_picks = env.num_rounds * env.num_teams\n",
    "\n",
    "    while not done and pick_count < max_picks:\n",
    "        if np.random.rand() <= epsilon:\n",
    "            action = random.randrange(len(env.available_players))\n",
    "        else:\n",
    "            probabilities = model.predict(state).flatten()\n",
    "            probabilities = np.nan_to_num(probabilities, nan=0.0)\n",
    "            probabilities /= np.sum(probabilities)\n",
    "            if np.isnan(probabilities).any() or np.any(probabilities < 0):\n",
    "                action = random.randrange(len(env.available_players))\n",
    "            else:\n",
    "                action = np.random.choice(len(env.available_players), p=probabilities[:len(env.available_players)])\n",
    "        \n",
    "        next_state, reward, done, _ = env.step(action)\n",
    "        next_state = np.reshape(next_state, [1, 6])\n",
    "        \n",
    "        replay_buffer.append((state, action, reward, next_state, done))\n",
    "        if len(replay_buffer) > buffer_size:\n",
    "            replay_buffer.pop(0)\n",
    "        \n",
    "        if len(replay_buffer) >= batch_size:\n",
    "            minibatch = random.sample(replay_buffer, batch_size)\n",
    "            for s, a, r, ns, d in minibatch:\n",
    "                target = r\n",
    "                if not d:\n",
    "                    target = r + gamma * np.amax(model.predict(ns.reshape(1, 6)))\n",
    "                \n",
    "                target_f = model.predict(s.reshape(1, 6))\n",
    "                target_f[0][a] = target\n",
    "                model.fit(s.reshape(1, 6), target_f, epochs=1, verbose=0)\n",
    "        \n",
    "        state = next_state\n",
    "        pick_count += 1\n",
    "    \n",
    "    if epsilon > epsilon_min:\n",
    "        epsilon *= epsilon_decay\n",
    "\n",
    "# Save the model\n",
    "model.save(\"nn_fantasy_baseball_model\")\n",
    "\n",
    "# Load the model\n",
    "model = tf.keras.models.load_model(\"nn_fantasy_baseball_model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dec3d241",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate a draft\n",
    "state = env.reset()\n",
    "done = False\n",
    "pick_count = 0  # Initialize pick counter\n",
    "max_picks = env.num_rounds * env.num_teams  # Total number of picks\n",
    "\n",
    "while not done and pick_count < max_picks:\n",
    "    state = np.reshape(state, [1, 6])  # Adjusted to match input dimensions\n",
    "    probabilities = model.predict(state).flatten()\n",
    "    probabilities = np.nan_to_num(probabilities, nan=0.0)\n",
    "    probabilities /= np.sum(probabilities)\n",
    "    if np.isnan(probabilities).any() or np.any(probabilities < 0):\n",
    "        action = random.randrange(len(env.available_players))\n",
    "    else:\n",
    "        action = np.random.choice(len(env.available_players), p=probabilities[:len(env.available_players)])\n",
    "    \n",
    "    state, reward, done, _ = env.step(action)\n",
    "    env.render()\n",
    "    pick_count += 1  # Increment pick counter\n",
    "\n",
    "    if pick_count >= max_picks:\n",
    "        done = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d45a98d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90e1af5d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
